{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:15.618227100Z",
     "start_time": "2023-11-25T11:29:15.579458900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:15.713213300Z",
     "start_time": "2023-11-25T11:29:15.593979500Z"
    }
   },
   "outputs": [],
   "source": [
    "# In real-world scenarios, learning how the data was generated is impractical. Do not rely on this function while doing research.\n",
    "def generate_data(dim, num):\n",
    "    np.random.seed(1)\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "    np.random.seed(3)\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:15.724216100Z",
     "start_time": "2023-11-25T11:29:15.600223600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Modifying the overall structure is acceptable but not recommended\n",
    "#SMO 算法\n",
    "class SVM1:\n",
    "    def __init__(self,C,tol,num_epoches=1000):\n",
    "        \"\"\"\n",
    "        :param C:Upper Bound of Lagrange Multiplier C>0\n",
    "        :param tol: tolerance of KKT condition  0<tol<1\n",
    "        \"\"\"\n",
    "        #self.coef = np.zeros(num_features)\n",
    "        #self.intercept = 0\n",
    "        #self.alpha=np.zeros(num_samples)\n",
    "        self.C=C\n",
    "        self.tol=tol\n",
    "        self.num_epoches=num_epoches\n",
    "        \n",
    "    def func(self,x):\n",
    "        return np.dot(x,self.coef.T)+self.intercept\n",
    "    \n",
    "    def KKT_i(self,x_i,y_i,a_i):\n",
    "        #if 满足KKT条件，返回True，0\n",
    "        #else 返回False，np.abs(1-y_i*func(coef,intercept,x_i))\n",
    "        if a_i<0:\n",
    "            print(f'alpha_i={a_i}<0')\n",
    "            print(f\"ERROR:alpha_i={a_i}<0\\n\\n\")\n",
    "            return False,None\n",
    "        elif a_i>=0 and a_i<=self.C:\n",
    "            if np.abs(1-y_i*self.func(x_i))<self.tol:\n",
    "                return True,0\n",
    "            else:\n",
    "                return False,np.abs(1-y_i*self.func(x_i))\n",
    "        else:\n",
    "            print(f'alpha_i={a_i}>{self.C}')\n",
    "            print(f\"ERROR:alpha_i={a_i}>{self.C}\\n\\n\")\n",
    "            return False,None\n",
    "    def KKT(self,X,y):\n",
    "        # X应为np.array(num_samples,num_features)\n",
    "        # y应为np.array(num_samples)\n",
    "        # alpha应为np.array(num_samples)\n",
    "        # coef应为np.array(num_features)\n",
    "        # intercept应为np.array(1)\n",
    "        # if 每一个X[i,:],y[i,0],alpha[i]都满足KKT条件，返回True\n",
    "        # else 返回False，违背KKT条件最严重的那个样本的index，其中违背的程度被记录在KKT_i的第二个返回值中\n",
    "        #用state记录是否全部样本满足KKT条件\n",
    "        STATE=True\n",
    "        GAP=np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            state,gap=self.KKT_i(X[i,:],y[i],self.alpha[i])\n",
    "            GAP[i]=gap\n",
    "            if state==False:\n",
    "                STATE=False\n",
    "        #print(GAP)\n",
    "        if STATE==True:\n",
    "            return True,-1\n",
    "        else:\n",
    "            return False,np.random.choice(np.where(GAP==np.max(GAP))[0])\n",
    "        \n",
    "    def clipping(self,alpha,low,high):#注意这里要写self\n",
    "        if alpha<low:\n",
    "            return low\n",
    "        elif alpha>high:\n",
    "            return high\n",
    "        else:\n",
    "            return alpha\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        num_features=X.shape[1]\n",
    "        num_samples=X.shape[0]\n",
    "        self.coef = np.zeros(num_features)\n",
    "        self.intercept = 0\n",
    "        self.alpha=np.zeros(num_samples)\n",
    "        for epoch in range(self.num_epoches):\n",
    "            #验证是否全部样本满足KKT条件\n",
    "            state,index=self.KKT(X,y)\n",
    "            if state==True:\n",
    "                break\n",
    "            else:\n",
    "                i=index \n",
    "                #选择第二个样本\n",
    "                E=np.zeros(X.shape[0])\n",
    "                for k in range(X.shape[0]):\n",
    "                    E[k]=self.func(X[k,:])-y[k]\n",
    "                #j=np.argmax(np.abs(E-E[i]))\n",
    "                j=np.random.choice(np.where(np.abs(E[i]-E)==np.max(np.abs(E[i]-E)))[0])\n",
    "                assert j!=i,'Error: j==i, please check the code'\n",
    "                #固定其他样本的alpha，更新alpha_i,alpha_j\n",
    "                nita=1/(np.dot(X[i,:],X[i,:])+np.dot(X[j,:],X[j,:])-2*np.dot(X[i,:],X[j,:]))\n",
    "                assert nita>0,'Error: nita<=0, please check the code'\n",
    "                alpha_j_new_uncut=self.alpha[j]+y[j]*(E[i]-E[j])*nita\n",
    "                #计算low和high\n",
    "                if y[i]==y[j]:\n",
    "                    low=max(0,self.alpha[i]+self.alpha[j]-self.C)\n",
    "                    high=min(self.C,self.alpha[i]+self.alpha[j])\n",
    "                else:\n",
    "                    low=max(0,self.alpha[j]-self.alpha[i])\n",
    "                    high=min(self.C,self.C+self.alpha[j]-self.alpha[i])\n",
    "                #修剪alpha_j_new\n",
    "                alpha_j_new=self.clipping(alpha_j_new_uncut,low,high)#报错？说是我放进去了4个参数，但是只有3个参数。后来发现是因为我把self放进去了,clipping函数一开始没写self\n",
    "                alpha_i_new=self.alpha[i]+y[i]*y[j]*(self.alpha[j]-alpha_j_new)\n",
    "                #更新coef\n",
    "                #coef_new=coef+y[i]*(alpha_i_new-alpha[i])*X[i,:]+y[j]*(alpha_j_new-alpha[j])*X[j,:]\n",
    "                #更新intercept\n",
    "                b_i_new=self.intercept-E[i]-y[i]*(alpha_i_new-self.alpha[i])*np.dot(X[i,:],X[i,:])-y[j]*(alpha_j_new-self.alpha[j])*np.dot(X[i,:],X[j,:])\n",
    "                b_j_new=self.intercept-E[j]-y[i]*(alpha_i_new-self.alpha[i])*np.dot(X[i,:],X[j,:])-y[j]*(alpha_j_new-self.alpha[j])*np.dot(X[j,:],X[j,:])\n",
    "                #选择新的intercept\n",
    "                if alpha_i_new>0 and alpha_i_new<self.C:\n",
    "                    intercept_new=b_i_new\n",
    "                elif alpha_j_new>0 and alpha_j_new<self.C:\n",
    "                    intercept_new=b_j_new\n",
    "                else:\n",
    "                    intercept_new=(b_i_new+b_j_new)/2\n",
    "                #更新alpha\n",
    "                self.alpha[i]=alpha_i_new\n",
    "                self.alpha[j]=alpha_j_new\n",
    "                #更新coef\n",
    "                #coef=coef_new\n",
    "                #更新intercept\n",
    "                self.intercept=intercept_new\n",
    "                #print(f'epoch={epoch},i={i},j={j},\\nalpha_{i}_new={alpha_i_new},alpha_{j}_new={alpha_j_new},intercept={self.intercept}\\n\\n')\n",
    "        \n",
    "        #更新coef:\n",
    "        self.coef=np.zeros(X.shape[1])\n",
    "        for i in range(X.shape[0]):\n",
    "            self.coef+=self.alpha[i]*y[i]*X[i,:]\n",
    "        print(f'self.coef={self.coef}')\n",
    "        print(f'self.intercept={self.intercept}')\n",
    "        \n",
    "        \n",
    "    def predict(self, X, y,Train=False):\n",
    "        if Train==True:\n",
    "            str='train set'\n",
    "        elif Train==False:\n",
    "            str='test set'\n",
    "        else:\n",
    "            print('ERROR:Train should be True or False')\n",
    "        y_pred = np.sign(self.func(X))\n",
    "        #correct rate\n",
    "        print(f'{str} accuracy:\\n{np.sum([y * y_pred >= 0])/len(X)}')\n",
    "        print(f'infact mislabeled num:{np.sum([y * y_pred < 0])},{str} num:{len(X)}')\n",
    "        #返回数据框\n",
    "        return pd.DataFrame({'y_pred':y_pred,'y':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:15.738362700Z",
     "start_time": "2023-11-25T11:29:15.631350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient Descent 算法\n",
    "class SVM2:\n",
    "    def __init__(self,num_epoches=150,lr=0.001,decay=0.05):\n",
    "        self.num_epoches=num_epoches\n",
    "        self.lr=lr\n",
    "        self.decay=decay\n",
    "        \n",
    "    def func(self,x):\n",
    "        return np.dot(x,self.coef.T)+self.intercept\n",
    "    \n",
    "    def target_function(self,X,y):\n",
    "        return np.sum(self.alpha)-0.5*np.dot(np.dot(self.alpha*y,X),np.dot(self.alpha*y,X).T)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        target=0\n",
    "        num_features=X.shape[1]\n",
    "        num_samples=X.shape[0]\n",
    "        self.coef = np.zeros(num_features)\n",
    "        self.intercept = 0\n",
    "        self.alpha = np.zeros(num_samples)\n",
    "        for epoch in range(self.num_epoches):\n",
    "            pre_target=target\n",
    "            grad_alpha=np.ones(X.shape[0])-np.dot(np.dot(self.alpha*y,X),X.T)*y\n",
    "            grad_alpha=grad_alpha.reshape(-1,1)\n",
    "            self.alpha+=self.lr*grad_alpha.reshape(-1,)\n",
    "            self.coef=np.dot(X.T,self.alpha*y)\n",
    "            self.intercept=np.sum(self.alpha*y)\n",
    "            target=self.target_function(X,y)\n",
    "            if target<pre_target:\n",
    "                self.lr*=0.05\n",
    "            print('epoch: {}, target: {}'.format(epoch, target))\n",
    "            if self.lr<1e-7:\n",
    "                break\n",
    "        \n",
    "    def predict(self, X, y,Train=False):\n",
    "        if Train==True:\n",
    "            str='train set'\n",
    "        elif Train==False:\n",
    "            str='test set'\n",
    "        else:\n",
    "            print('ERROR:Train should be True or False')\n",
    "        y_pred = np.sign(self.func(X))\n",
    "        #correct rate\n",
    "        print(f'{str} accuracy:\\n{np.sum([y * y_pred >= 0])/len(X)}')\n",
    "        print(f'infact mislabeled num:{np.sum([y * y_pred < 0])},{str} num:{len(X)}')\n",
    "        #返回数据框\n",
    "        return pd.DataFrame({'y_pred':y_pred,'y':y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:29:15.751369900Z",
     "start_time": "2023-11-25T11:29:15.647199200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mislabel rate:0.0362\n",
      "X_train.shape:(8000, 20),y_train.shape:(8000,)\n",
      "X_test.shape:(2000, 20),y_test.shape:(2000,)\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "num_features, num_samples = 20, 10000\n",
    "split_rate = 0.8\n",
    "X, y, mislabel = generate_data(dim=num_features, num=num_samples)\n",
    "print(f'mislabel rate:{mislabel}')\n",
    "y = y.reshape(-1, )\n",
    "X_std = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "X_train, y_train = X[:int(split_rate * len(y))], y[:int(split_rate * len(y))]\n",
    "X_test, y_test = X[int(split_rate * len(y)):], y[int(split_rate * len(y)):]\n",
    "X_train_std, X_test_std = X_std[:int(split_rate * len(y))], X_std[int(split_rate * len(y)):]\n",
    "print(f'X_train.shape:{X_train.shape},y_train.shape:{y_train.shape}')\n",
    "print(f'X_test.shape:{X_test.shape},y_test.shape:{y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.coef=[ 0.01719161  0.49146618 -0.89159247 -0.04808921  1.31688291  1.2633268\n",
      " -1.23353559 -0.96306783 -1.5568798  -0.27924405 -1.63717165 -0.13348756\n",
      "  0.57195046 -0.89801116  0.3423029   0.50739982 -1.18616736  0.2674257\n",
      " -0.83847034 -0.30212554]\n",
      "self.intercept=0.1324866365912034\n",
      "训练过程用时:45.18s\n"
     ]
    }
   ],
   "source": [
    "model1 = SVM1(C=5,tol=1e-4,num_epoches=500)\n",
    "start_time=time.time()\n",
    "model1.fit(X_train,y_train)\n",
    "end_time=time.time()\n",
    "duration_smo=end_time-start_time\n",
    "print(f'训练过程用时:{duration_smo:.2f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:00.940264200Z",
     "start_time": "2023-11-25T11:29:15.741364800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, target: -475.17183033489397\n",
      "epoch: 1, target: -169108.38294729317\n",
      "epoch: 2, target: -566.6064057916248\n",
      "epoch: 3, target: -1.2270783373822658\n",
      "epoch: 4, target: 1.6469084044141187\n",
      "epoch: 5, target: 1.6680218158907443\n",
      "epoch: 6, target: 1.6720604690925804\n",
      "epoch: 7, target: 1.6759882191876547\n",
      "epoch: 8, target: 1.679915215720204\n",
      "epoch: 9, target: 1.6838422069831038\n",
      "epoch: 10, target: 1.6877691982083944\n",
      "epoch: 11, target: 1.6916961894334122\n",
      "epoch: 12, target: 1.6956231806584279\n",
      "epoch: 13, target: 1.6995501718834438\n",
      "epoch: 14, target: 1.7034771631084595\n",
      "epoch: 15, target: 1.7074041543334757\n",
      "epoch: 16, target: 1.7113311455584912\n",
      "epoch: 17, target: 1.7152581367835071\n",
      "epoch: 18, target: 1.7191851280085229\n",
      "epoch: 19, target: 1.7231121192335386\n",
      "epoch: 20, target: 1.7270391104585545\n",
      "epoch: 21, target: 1.7309661016835702\n",
      "epoch: 22, target: 1.734893092908586\n",
      "epoch: 23, target: 1.738820084133602\n",
      "epoch: 24, target: 1.7427470753586176\n",
      "epoch: 25, target: 1.7466740665836333\n",
      "epoch: 26, target: 1.750601057808649\n",
      "epoch: 27, target: 1.754528049033665\n",
      "epoch: 28, target: 1.758455040258681\n",
      "epoch: 29, target: 1.7623820314836967\n",
      "epoch: 30, target: 1.7663090227087124\n",
      "epoch: 31, target: 1.7702360139337283\n",
      "epoch: 32, target: 1.774163005158744\n",
      "epoch: 33, target: 1.7780899963837598\n",
      "epoch: 34, target: 1.7820169876087757\n",
      "epoch: 35, target: 1.7859439788337914\n",
      "epoch: 36, target: 1.7898709700588074\n",
      "epoch: 37, target: 1.7937979612838229\n",
      "epoch: 38, target: 1.7977249525088388\n",
      "epoch: 39, target: 1.8016519437338547\n",
      "epoch: 40, target: 1.8055789349588705\n",
      "epoch: 41, target: 1.8095059261838862\n",
      "epoch: 42, target: 1.8134329174089021\n",
      "epoch: 43, target: 1.8173599086339178\n",
      "epoch: 44, target: 1.8212868998589338\n",
      "epoch: 45, target: 1.8252138910839495\n",
      "epoch: 46, target: 1.8291408823089652\n",
      "epoch: 47, target: 1.8330678735339812\n",
      "epoch: 48, target: 1.8369948647589969\n",
      "epoch: 49, target: 1.8409218559840126\n",
      "epoch: 50, target: 1.8448488472090285\n",
      "epoch: 51, target: 1.8487758384340442\n",
      "epoch: 52, target: 1.85270282965906\n",
      "epoch: 53, target: 1.8566298208840757\n",
      "epoch: 54, target: 1.8605568121090919\n",
      "epoch: 55, target: 1.8644838033341076\n",
      "epoch: 56, target: 1.8684107945591233\n",
      "epoch: 57, target: 1.872337785784139\n",
      "epoch: 58, target: 1.8762647770091547\n",
      "epoch: 59, target: 1.8801917682341707\n",
      "epoch: 60, target: 1.8841187594591866\n",
      "epoch: 61, target: 1.8880457506842023\n",
      "epoch: 62, target: 1.891972741909218\n",
      "epoch: 63, target: 1.8958997331342338\n",
      "epoch: 64, target: 1.8998267243592495\n",
      "epoch: 65, target: 1.9037537155842656\n",
      "epoch: 66, target: 1.9076807068092811\n",
      "epoch: 67, target: 1.911607698034297\n",
      "epoch: 68, target: 1.915534689259313\n",
      "epoch: 69, target: 1.919461680484329\n",
      "epoch: 70, target: 1.9233886717093445\n",
      "epoch: 71, target: 1.9273156629343602\n",
      "epoch: 72, target: 1.9312426541593761\n",
      "epoch: 73, target: 1.9351696453843918\n",
      "epoch: 74, target: 1.9390966366094078\n",
      "epoch: 75, target: 1.9430236278344235\n",
      "epoch: 76, target: 1.9469506190594394\n",
      "epoch: 77, target: 1.9508776102844552\n",
      "epoch: 78, target: 1.9548046015094709\n",
      "epoch: 79, target: 1.9587315927344866\n",
      "epoch: 80, target: 1.9626585839595025\n",
      "epoch: 81, target: 1.9665855751845183\n",
      "epoch: 82, target: 1.9705125664095342\n",
      "epoch: 83, target: 1.97443955763455\n",
      "epoch: 84, target: 1.9783665488595656\n",
      "epoch: 85, target: 1.9822935400845816\n",
      "epoch: 86, target: 1.9862205313095975\n",
      "epoch: 87, target: 1.9901475225346132\n",
      "epoch: 88, target: 1.9940745137596287\n",
      "epoch: 89, target: 1.9980015049846447\n",
      "epoch: 90, target: 2.0019284962096604\n",
      "epoch: 91, target: 2.005855487434676\n",
      "epoch: 92, target: 2.009782478659692\n",
      "epoch: 93, target: 2.013709469884708\n",
      "epoch: 94, target: 2.017636461109724\n",
      "epoch: 95, target: 2.02156345233474\n",
      "epoch: 96, target: 2.025490443559755\n",
      "epoch: 97, target: 2.029417434784771\n",
      "epoch: 98, target: 2.033344426009787\n",
      "epoch: 99, target: 2.0372714172348028\n",
      "epoch: 100, target: 2.0411984084598185\n",
      "epoch: 101, target: 2.045125399684834\n",
      "epoch: 102, target: 2.0490523909098504\n",
      "epoch: 103, target: 2.0529793821348656\n",
      "epoch: 104, target: 2.0569063733598814\n",
      "epoch: 105, target: 2.0608333645848975\n",
      "epoch: 106, target: 2.0647603558099132\n",
      "epoch: 107, target: 2.0686873470349294\n",
      "epoch: 108, target: 2.072614338259945\n",
      "epoch: 109, target: 2.076541329484961\n",
      "epoch: 110, target: 2.0804683207099766\n",
      "epoch: 111, target: 2.0843953119349923\n",
      "epoch: 112, target: 2.088322303160008\n",
      "epoch: 113, target: 2.0922492943850237\n",
      "epoch: 114, target: 2.0961762856100394\n",
      "epoch: 115, target: 2.1001032768350556\n",
      "epoch: 116, target: 2.1040302680600718\n",
      "epoch: 117, target: 2.1079572592850875\n",
      "epoch: 118, target: 2.111884250510103\n",
      "epoch: 119, target: 2.115811241735119\n",
      "epoch: 120, target: 2.1197382329601346\n",
      "epoch: 121, target: 2.1236652241851504\n",
      "epoch: 122, target: 2.127592215410166\n",
      "epoch: 123, target: 2.131519206635182\n",
      "epoch: 124, target: 2.1354461978601975\n",
      "epoch: 125, target: 2.1393731890852137\n",
      "epoch: 126, target: 2.143300180310229\n",
      "epoch: 127, target: 2.1472271715352456\n",
      "epoch: 128, target: 2.151154162760261\n",
      "epoch: 129, target: 2.1550811539852766\n",
      "epoch: 130, target: 2.1590081452102927\n",
      "epoch: 131, target: 2.1629351364353084\n",
      "epoch: 132, target: 2.166862127660324\n",
      "epoch: 133, target: 2.17078911888534\n",
      "epoch: 134, target: 2.174716110110356\n",
      "epoch: 135, target: 2.1786431013353718\n",
      "epoch: 136, target: 2.182570092560387\n",
      "epoch: 137, target: 2.186497083785403\n",
      "epoch: 138, target: 2.1904240750104194\n",
      "epoch: 139, target: 2.194351066235435\n",
      "epoch: 140, target: 2.198278057460451\n",
      "epoch: 141, target: 2.2022050486854665\n",
      "epoch: 142, target: 2.2061320399104827\n",
      "epoch: 143, target: 2.2100590311354984\n",
      "epoch: 144, target: 2.2139860223605137\n",
      "epoch: 145, target: 2.2179130135855294\n",
      "epoch: 146, target: 2.221840004810546\n",
      "epoch: 147, target: 2.2257669960355613\n",
      "epoch: 148, target: 2.2296939872605774\n",
      "epoch: 149, target: 2.233620978485593\n",
      "训练过程用时:0.43s\n"
     ]
    }
   ],
   "source": [
    "model2 = SVM2(num_epoches=150,lr=0.0005,decay=0.1)\n",
    "start_time=time.time()\n",
    "model2.fit(X_train, y_train)\n",
    "end_time=time.time()\n",
    "duration_gd=end_time-start_time\n",
    "print(f'训练过程用时:{duration_gd:.2f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:01.423604Z",
     "start_time": "2023-11-25T11:30:00.933261500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1:SMO algorithm\n",
      "train set accuracy:\n",
      "0.9205\n",
      "infact mislabeled num:636,train set num:8000\n",
      "test set accuracy:\n",
      "0.922\n",
      "infact mislabeled num:156,test set num:2000\n"
     ]
    },
    {
     "data": {
      "text/plain": "      y_pred    y\n0       -1.0 -1.0\n1        1.0  1.0\n2        1.0  1.0\n3        1.0  1.0\n4       -1.0 -1.0\n...      ...  ...\n1995    -1.0 -1.0\n1996     1.0  1.0\n1997     1.0  1.0\n1998    -1.0 -1.0\n1999     1.0  1.0\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_pred</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "print('model1:SMO algorithm')\n",
    "model1.predict(X_train, y_train, Train=True)\n",
    "model1.predict(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:01.470616Z",
     "start_time": "2023-11-25T11:30:01.369126700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:01.527630600Z",
     "start_time": "2023-11-25T11:30:01.397102300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model2:Gradient Descent algorithm\n",
      "train set accuracy:\n",
      "0.94825\n",
      "infact mislabeled num:414,train set num:8000\n",
      "test set accuracy:\n",
      "0.9385\n",
      "infact mislabeled num:123,test set num:2000\n"
     ]
    },
    {
     "data": {
      "text/plain": "      y_pred    y\n0       -1.0 -1.0\n1        1.0  1.0\n2        1.0  1.0\n3        1.0  1.0\n4       -1.0 -1.0\n...      ...  ...\n1995    -1.0 -1.0\n1996     1.0  1.0\n1997     1.0  1.0\n1998    -1.0 -1.0\n1999     1.0  1.0\n\n[2000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_pred</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "print('model2:Gradient Descent algorithm')\n",
    "model2.predict(X_train, y_train, Train=True)\n",
    "model2.predict(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf.coef_=[[ 0.02274071  0.09404098 -0.1064336   0.00202636  0.18287085  0.1882266\n",
      "  -0.17106342 -0.1420816  -0.2126855  -0.03034664 -0.22178982 -0.01407329\n",
      "   0.06690528 -0.10493372  0.08157887  0.04348746 -0.22365544  0.01925659\n",
      "  -0.11411043 -0.03441737]]\n",
      "clf.intercept_=[-9.99186188e-05]\n",
      "testset accuracy:0.951\n",
      "用时:22.488031148910522\n"
     ]
    }
   ],
   "source": [
    "#compare with sklearn,并计算时间\n",
    "start_time=time.time()\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "end_time=time.time()\n",
    "print(f'clf.coef_={clf.coef_}')\n",
    "print(f'clf.intercept_={clf.intercept_}')\n",
    "df_support_vectors=pd.DataFrame(clf.support_vectors_.tolist())\n",
    "print(f'testset accuracy:{clf.score(X_test,y_test)}')\n",
    "duration_sklearn=end_time-start_time\n",
    "print(f'用时:{duration_sklearn}:.2f')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:24.012604400Z",
     "start_time": "2023-11-25T11:30:01.423604Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "             0          1          2          3          4          5   \\\n0     -2.223281  -2.007581   1.865614   4.100516   1.982997   1.190086   \n1     -4.008782   8.240056  -5.623054  19.548781 -13.319517 -17.606886   \n2      0.722519  10.097873 -15.569416  -6.124421  -1.393518  -7.285375   \n3     -2.222195   9.083397  -1.586068   6.953060  -1.142183  -1.897672   \n4      0.663927   5.406022 -13.188968   8.454264   1.310922   3.490837   \n...         ...        ...        ...        ...        ...        ...   \n1313 -22.063162  22.288755   7.709771  -4.198827  -7.520452   4.956501   \n1314   5.309228   6.522368  -5.596859  -6.032238  -8.548780   9.272599   \n1315   8.818781  -3.237233  -4.894439   2.398958 -12.368448   5.795863   \n1316  16.874231  15.231831   4.707415  10.695622   2.737454 -11.643657   \n1317  -7.963925 -10.632989  -2.730967 -11.338426 -18.493194   7.446920   \n\n             6          7          8          9          10         11  \\\n0     -6.706623   3.775638   1.218213  11.294839  11.989179   1.851564   \n1    -16.507213  -8.905556 -11.191154  19.560789  -3.264995 -13.426758   \n2      5.311638   0.040008   3.212659  -7.252149  15.365363  -0.003750   \n3     12.591335  -7.519774  -2.830529 -12.927374   0.967394  10.695010   \n4      4.040681   5.124341  11.203618   8.604544   4.869104  -7.643396   \n...         ...        ...        ...        ...        ...        ...   \n1313  -6.177335  -0.373615 -15.021083  -1.099379   0.221363   9.919162   \n1314  15.140683   7.823205  -3.414320  12.725956   5.722150  13.983760   \n1315  12.562584 -12.341323  14.695609  18.516630   3.380304   3.061986   \n1316  -4.609053   2.071136   1.920710  -5.010482  -3.073552   1.005002   \n1317  -4.611518 -17.549237  -1.578938  -7.129039  -2.666920   8.454513   \n\n             12         13         14         15         16         17  \\\n0     -3.752850  -6.387304   4.234944   0.773401  -3.438537   0.435969   \n1     11.143830  -5.865239 -12.368534   8.758389   6.233622  -4.349567   \n2     12.935496  -4.389977   5.900395  -6.793838  -9.509093  -7.043503   \n3      6.814019   7.340118  10.530424   6.252182   7.582594   4.037241   \n4      2.863311  -5.578340 -14.487523  -0.413769  -9.128101  11.351414   \n...         ...        ...        ...        ...        ...        ...   \n1313  -6.048613 -10.875043  12.125939 -28.363086  12.978091   6.315078   \n1314   7.234502 -13.056546  -1.098291 -10.638276  -1.546051  -1.409231   \n1315  -2.469387  -7.355258   8.026687   4.560838 -17.343922  14.650620   \n1316  -5.610403  -8.634869  -4.660314  -8.354574   1.415778  17.341982   \n1317  10.716487   3.799773  -1.543285  -0.379920 -10.785728 -11.151459   \n\n             18         19  \n0     -6.200008   6.980320  \n1     14.075400   1.291016  \n2     -0.458667  -2.187335  \n3     -9.753885   5.260951  \n4     -0.377092   0.452626  \n...         ...        ...  \n1313  11.285702  11.148314  \n1314 -16.778285 -10.494791  \n1315  -8.671666   3.911934  \n1316  -1.643440   0.613246  \n1317  29.062667  -9.141312  \n\n[1318 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-2.223281</td>\n      <td>-2.007581</td>\n      <td>1.865614</td>\n      <td>4.100516</td>\n      <td>1.982997</td>\n      <td>1.190086</td>\n      <td>-6.706623</td>\n      <td>3.775638</td>\n      <td>1.218213</td>\n      <td>11.294839</td>\n      <td>11.989179</td>\n      <td>1.851564</td>\n      <td>-3.752850</td>\n      <td>-6.387304</td>\n      <td>4.234944</td>\n      <td>0.773401</td>\n      <td>-3.438537</td>\n      <td>0.435969</td>\n      <td>-6.200008</td>\n      <td>6.980320</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-4.008782</td>\n      <td>8.240056</td>\n      <td>-5.623054</td>\n      <td>19.548781</td>\n      <td>-13.319517</td>\n      <td>-17.606886</td>\n      <td>-16.507213</td>\n      <td>-8.905556</td>\n      <td>-11.191154</td>\n      <td>19.560789</td>\n      <td>-3.264995</td>\n      <td>-13.426758</td>\n      <td>11.143830</td>\n      <td>-5.865239</td>\n      <td>-12.368534</td>\n      <td>8.758389</td>\n      <td>6.233622</td>\n      <td>-4.349567</td>\n      <td>14.075400</td>\n      <td>1.291016</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.722519</td>\n      <td>10.097873</td>\n      <td>-15.569416</td>\n      <td>-6.124421</td>\n      <td>-1.393518</td>\n      <td>-7.285375</td>\n      <td>5.311638</td>\n      <td>0.040008</td>\n      <td>3.212659</td>\n      <td>-7.252149</td>\n      <td>15.365363</td>\n      <td>-0.003750</td>\n      <td>12.935496</td>\n      <td>-4.389977</td>\n      <td>5.900395</td>\n      <td>-6.793838</td>\n      <td>-9.509093</td>\n      <td>-7.043503</td>\n      <td>-0.458667</td>\n      <td>-2.187335</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-2.222195</td>\n      <td>9.083397</td>\n      <td>-1.586068</td>\n      <td>6.953060</td>\n      <td>-1.142183</td>\n      <td>-1.897672</td>\n      <td>12.591335</td>\n      <td>-7.519774</td>\n      <td>-2.830529</td>\n      <td>-12.927374</td>\n      <td>0.967394</td>\n      <td>10.695010</td>\n      <td>6.814019</td>\n      <td>7.340118</td>\n      <td>10.530424</td>\n      <td>6.252182</td>\n      <td>7.582594</td>\n      <td>4.037241</td>\n      <td>-9.753885</td>\n      <td>5.260951</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.663927</td>\n      <td>5.406022</td>\n      <td>-13.188968</td>\n      <td>8.454264</td>\n      <td>1.310922</td>\n      <td>3.490837</td>\n      <td>4.040681</td>\n      <td>5.124341</td>\n      <td>11.203618</td>\n      <td>8.604544</td>\n      <td>4.869104</td>\n      <td>-7.643396</td>\n      <td>2.863311</td>\n      <td>-5.578340</td>\n      <td>-14.487523</td>\n      <td>-0.413769</td>\n      <td>-9.128101</td>\n      <td>11.351414</td>\n      <td>-0.377092</td>\n      <td>0.452626</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1313</th>\n      <td>-22.063162</td>\n      <td>22.288755</td>\n      <td>7.709771</td>\n      <td>-4.198827</td>\n      <td>-7.520452</td>\n      <td>4.956501</td>\n      <td>-6.177335</td>\n      <td>-0.373615</td>\n      <td>-15.021083</td>\n      <td>-1.099379</td>\n      <td>0.221363</td>\n      <td>9.919162</td>\n      <td>-6.048613</td>\n      <td>-10.875043</td>\n      <td>12.125939</td>\n      <td>-28.363086</td>\n      <td>12.978091</td>\n      <td>6.315078</td>\n      <td>11.285702</td>\n      <td>11.148314</td>\n    </tr>\n    <tr>\n      <th>1314</th>\n      <td>5.309228</td>\n      <td>6.522368</td>\n      <td>-5.596859</td>\n      <td>-6.032238</td>\n      <td>-8.548780</td>\n      <td>9.272599</td>\n      <td>15.140683</td>\n      <td>7.823205</td>\n      <td>-3.414320</td>\n      <td>12.725956</td>\n      <td>5.722150</td>\n      <td>13.983760</td>\n      <td>7.234502</td>\n      <td>-13.056546</td>\n      <td>-1.098291</td>\n      <td>-10.638276</td>\n      <td>-1.546051</td>\n      <td>-1.409231</td>\n      <td>-16.778285</td>\n      <td>-10.494791</td>\n    </tr>\n    <tr>\n      <th>1315</th>\n      <td>8.818781</td>\n      <td>-3.237233</td>\n      <td>-4.894439</td>\n      <td>2.398958</td>\n      <td>-12.368448</td>\n      <td>5.795863</td>\n      <td>12.562584</td>\n      <td>-12.341323</td>\n      <td>14.695609</td>\n      <td>18.516630</td>\n      <td>3.380304</td>\n      <td>3.061986</td>\n      <td>-2.469387</td>\n      <td>-7.355258</td>\n      <td>8.026687</td>\n      <td>4.560838</td>\n      <td>-17.343922</td>\n      <td>14.650620</td>\n      <td>-8.671666</td>\n      <td>3.911934</td>\n    </tr>\n    <tr>\n      <th>1316</th>\n      <td>16.874231</td>\n      <td>15.231831</td>\n      <td>4.707415</td>\n      <td>10.695622</td>\n      <td>2.737454</td>\n      <td>-11.643657</td>\n      <td>-4.609053</td>\n      <td>2.071136</td>\n      <td>1.920710</td>\n      <td>-5.010482</td>\n      <td>-3.073552</td>\n      <td>1.005002</td>\n      <td>-5.610403</td>\n      <td>-8.634869</td>\n      <td>-4.660314</td>\n      <td>-8.354574</td>\n      <td>1.415778</td>\n      <td>17.341982</td>\n      <td>-1.643440</td>\n      <td>0.613246</td>\n    </tr>\n    <tr>\n      <th>1317</th>\n      <td>-7.963925</td>\n      <td>-10.632989</td>\n      <td>-2.730967</td>\n      <td>-11.338426</td>\n      <td>-18.493194</td>\n      <td>7.446920</td>\n      <td>-4.611518</td>\n      <td>-17.549237</td>\n      <td>-1.578938</td>\n      <td>-7.129039</td>\n      <td>-2.666920</td>\n      <td>8.454513</td>\n      <td>10.716487</td>\n      <td>3.799773</td>\n      <td>-1.543285</td>\n      <td>-0.379920</td>\n      <td>-10.785728</td>\n      <td>-11.151459</td>\n      <td>29.062667</td>\n      <td>-9.141312</td>\n    </tr>\n  </tbody>\n</table>\n<p>1318 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#打印出支持向量\n",
    "df_support_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T11:30:24.041203700Z",
     "start_time": "2023-11-25T11:30:24.010112900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
